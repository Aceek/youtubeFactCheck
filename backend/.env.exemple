# Environment variables declared in this file are automatically made available to Prisma.
# See the documentation for more detail: https://pris.ly/d/prisma-schema#accessing-environment-variables-from-the-schema

# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.
# See the documentation for all the connection string options: https://pris.ly/d/connection-strings

# The following `prisma+postgres` URL is similar to the URL produced by running a local Prisma Postgres 
# server with the `prisma dev` CLI command, when not choosing any non-default ports or settings. The API key, unlike the 
# one found in a remote Prisma Postgres URL, does not contain any sensitive information.

DATABASE_URL= # Uncomment this line to use a dockerized PostgreSQL database
# DATABASE_URL= # Uncomment this line to use a local PostgreSQL database
YOUTUBE_API_KEY=
PORT=3001
ASSEMBLYAI_API_KEY=
OPENROUTER_API_KEY=
# Configuration pour le service d'extraction de faits
# Vous pouvez changer ce modèle pour tester d'autres options d'OpenRouter
# OPENROUTER_MODEL="mistralai/mistral-7b-instruct:free"
OPENROUTER_MODEL="moonshotai/kimi-dev-72b:free"
# Modèle pour la validation des claims (peut être différent du modèle d'extraction)
VALIDATION_MODEL="moonshotai/kimi-dev-72b:free"

DEBUG_MODE=true # Mettre à 'false' en production pour désactiver les logs de débogage

# Nombre de paragraphes à inclure dans chaque chunk pour l'extraction.
CHUNK_SIZE=6

# Nombre de paragraphes de chevauchement entre les chunks pour ne pas perdre le contexte.
CHUNK_OVERLAP=1

# Nombre de chunks à traiter en parallèle pour l'extraction et la validation.
# Augmenter cette valeur peut améliorer la vitesse, mais nécessite plus de ressources.
CONCURRENT_CHUNK_LIMIT=4

# Configuration du système de reprise sur erreur (Retry)
# Nombre maximum de tentatives pour un appel API qui a échoué
LLM_RETRY_COUNT=2
# Temps d'attente en millisecondes entre chaque tentative
LLM_RETRY_DELAY_MS=2000

# Pour l'API de recherche web Serper.
SERPER_API_KEY=
# Pour l'API Google Fact Check.
GOOGLE_API_KEY=
# Le nom du modèle LLM puissant qui sera utilisé comme "juge" pour le verdict final (ex: openai/gpt-4o).
FACT_CHECK_MODEL="moonshotai/kimi-dev-72b:free"

# Modèle rapide et peu coûteux pour générer les requêtes de recherche
SEARCH_QUERY_MODEL="mistralai/mistral-7b-instruct:free"

# Taille des lots pour la génération de requêtes de recherche
# Nombre de claims à traiter ensemble dans chaque appel LLM pour la génération de requêtes
SEARCH_QUERY_BATCH_SIZE=5