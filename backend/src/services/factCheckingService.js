const { OpenAI } = require('openai');
const fs = require('fs');
const path = require('path');
const prisma = require('../client');
const debugLogService = require('./debugLogService');
const webSearchService = require('./webSearchService');
const googleFactCheckService = require('./googleFactCheckService');
const { extractJsonFromString } = require('../utils/jsonUtils');

const openrouter = new OpenAI({
  baseURL: "https://openrouter.ai/api/v1",
  apiKey: process.env.OPENROUTER_API_KEY,
});

const factCheckPromptPath = path.join(__dirname, '../prompts/fact_check_verdict.prompt.txt');
const FACT_CHECK_PROMPT = fs.readFileSync(factCheckPromptPath, 'utf-8');

const searchQueriesPromptPath = path.join(__dirname, '../prompts/generate_search_queries.prompt.txt');
const SEARCH_QUERIES_PROMPT = fs.readFileSync(searchQueriesPromptPath, 'utf-8');

const sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

/**
 * Fonction utilitaire pour effectuer un appel LLM avec syst√®me de retry
 * @param {Function} apiCall - Fonction qui effectue l'appel API
 * @param {number} maxRetries - Nombre maximum de tentatives
 * @param {number} delayMs - D√©lai entre les tentatives en millisecondes
 * @param {string} context - Contexte pour les logs
 * @returns {Promise} R√©sultat de l'appel API
 */
async function callLLMWithRetry(apiCall, maxRetries, delayMs, context) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const result = await apiCall();
      if (attempt > 1) {
        console.log(`‚úÖ ${context}: Succ√®s √† la tentative ${attempt}/${maxRetries}`);
      }
      return result;
    } catch (error) {
      console.error(`‚ùå ${context}: Erreur √† la tentative ${attempt}/${maxRetries}: ${error.message}`);
      
      if (attempt === maxRetries) {
        console.error(`üí• ${context}: √âchec d√©finitif apr√®s ${maxRetries} tentatives`);
        throw error;
      }
      
      console.log(`‚è≥ ${context}: Attente de ${delayMs}ms avant la tentative ${attempt + 1}...`);
      await new Promise(resolve => setTimeout(resolve, delayMs));
    }
  }
}

/**
 * G√©n√®re des requ√™tes de recherche optimis√©es par lots avec journalisation d√©taill√©e
 * @param {Array} claims - Liste des claims √† traiter
 * @param {number} analysisId - ID de l'analyse pour les logs
 * @returns {Promise<Object>} Mapping claimId -> [requ√™tes de recherche]
 */
async function generateSearchQueries(claims, analysisId = null) {
  if (!claims || claims.length === 0) {
    return {};
  }

  console.log(`üîç G√©n√©ration de requ√™tes de recherche pour ${claims.length} claims`);

  const batchSize = parseInt(process.env.SEARCH_QUERY_BATCH_SIZE) || 5;
  const maxRetries = parseInt(process.env.LLM_RETRY_COUNT) || 3;
  const retryDelay = parseInt(process.env.LLM_RETRY_DELAY_MS) || 2000;
  const model = process.env.SEARCH_QUERY_MODEL || "mistralai/mistral-7b-instruct:free";
  const limit = parseInt(process.env.CONCURRENT_CHUNK_LIMIT) || 3;

  // D√©couper les claims en lots
  const batches = [];
  for (let i = 0; i < claims.length; i += batchSize) {
    batches.push(claims.slice(i, i + batchSize));
  }

  console.log(`üì¶ ${batches.length} lots g√©n√©r√©s pour la g√©n√©ration de requ√™tes (taille: ${batchSize})`);
  console.log(`üöÄ Traitement par lots : limite=${limit}, retries=${maxRetries}`);

  // Cr√©er les t√¢ches de traitement par lots
  const tasks = batches.map((batch, batchIndex) => async () => {
    const batchNumber = batchIndex + 1;
    console.log(`üîç Traitement du lot ${batchNumber}/${batches.length} (${batch.length} claims)`);
    
    const batchSubfolder = analysisId ? `query_generation/batch_${batchNumber}` : null;
    
    // Pr√©parer les claims pour le prompt
    const claimsForPrompt = batch.map(claim => ({
      claim_id: claim.id,
      text: claim.text
    }));

    const userPrompt = `Affirmations √† traiter : ${JSON.stringify(claimsForPrompt, null, 2)}`;

    // Sauvegarder le prompt pour ce lot
    if (analysisId && batchSubfolder) {
      debugLogService.log(
        analysisId,
        '1_prompt.txt',
        `--- PROMPT ENVOY√â AU MOD√àLE : ${model} ---\n--- LOT ${batchNumber} (${batch.length} claims) ---\n\n${SEARCH_QUERIES_PROMPT}\n\n${userPrompt}`,
        batchSubfolder
      );
    }

    try {
      const apiCall = async () => {
        const response = await openrouter.chat.completions.create({
          model: model,
          messages: [
            { role: "system", content: "Tu es un expert en g√©n√©ration de requ√™tes de recherche pour le fact-checking." },
            { role: "user", content: `${SEARCH_QUERIES_PROMPT}\n\n${userPrompt}` }
          ],
          response_format: { type: "json_object" },
          timeout: 30000,
        });

        if (!response.choices || response.choices.length === 0) {
          throw new Error("R√©ponse vide de l'API pour la g√©n√©ration de requ√™tes");
        }

        const rawJson = response.choices[0].message.content;
        
        // Sauvegarder la r√©ponse brute
        if (analysisId && batchSubfolder) {
          debugLogService.log(
            analysisId,
            '2_response.txt',
            rawJson,
            batchSubfolder
          );
        }

        const cleanedJson = extractJsonFromString(rawJson);
        
        if (!cleanedJson) {
          throw new Error("Impossible d'extraire un JSON valide de la r√©ponse");
        }

        const result = JSON.parse(cleanedJson);
        
        if (!result.queries || !Array.isArray(result.queries)) {
          throw new Error("Structure JSON invalide pour les requ√™tes");
        }

        return result.queries;
      };

      const queries = await callLLMWithRetry(
        apiCall,
        maxRetries,
        retryDelay,
        `G√©n√©ration requ√™tes lot ${batchNumber}`
      );

      console.log(`‚úÖ Lot ${batchNumber} trait√© avec succ√®s: ${queries.length} r√©sultats`);
      return { batchNumber, queries, success: true };

    } catch (error) {
      console.error(`‚ùå Erreur lors du traitement du lot ${batchNumber}:`, error.message);
      
      // Sauvegarder l'erreur
      if (analysisId && batchSubfolder) {
        debugLogService.log(
          analysisId,
          '2_response_FAILED.txt',
          `Erreur: ${error.message}`,
          batchSubfolder
        );
      }

      return { batchNumber, queries: [], success: false, error: error.message };
    }
  });

  // Ex√©cuter les t√¢ches par lots avec concurrence contr√¥l√©e
  let processedBatches = 0;
  const allResults = [];

  for (let i = 0; i < tasks.length; i += limit) {
    const batchTasks = tasks.slice(i, i + limit);
    const batchResults = await Promise.all(batchTasks.map(task => task()));
    allResults.push(...batchResults);
    
    processedBatches += batchTasks.length;
    console.log(`üìä Progr√®s g√©n√©ration requ√™tes: ${processedBatches}/${tasks.length} lots trait√©s`);
    
    // Pause entre les groupes de lots
    if (i + limit < tasks.length) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }

  // Construire le mapping final
  const queryMapping = {};
  let totalQueriesGenerated = 0;
  let successfulBatches = 0;

  for (const result of allResults) {
    if (result.success) {
      successfulBatches++;
      for (const queryData of result.queries) {
        if (queryData.claim_id && queryData.searches) {
          queryMapping[queryData.claim_id] = queryData.searches;
          totalQueriesGenerated += queryData.searches.length;
        }
      }
    }
  }

  // Fallback pour les claims sans requ√™tes g√©n√©r√©es
  let fallbackCount = 0;
  for (const claim of claims) {
    if (!queryMapping[claim.id]) {
      const basicQueries = [
        claim.text.substring(0, 50),
        `"${claim.text.split(' ').slice(0, 5).join(' ')}"`,
        claim.text.split(' ').slice(0, 3).join(' ') + ' v√©rification'
      ];
      queryMapping[claim.id] = basicQueries;
      fallbackCount++;
    }
  }

  // Cr√©er un rapport de synth√®se
  const summary = {
    totalClaims: claims.length,
    totalBatches: batches.length,
    successfulBatches: successfulBatches,
    failedBatches: batches.length - successfulBatches,
    totalQueriesGenerated: totalQueriesGenerated,
    fallbackQueriesUsed: fallbackCount,
    model: model,
    batchSize: batchSize,
    timestamp: new Date().toISOString()
  };

  // Sauvegarder le rapport de synth√®se
  if (analysisId) {
    debugLogService.log(
      analysisId,
      '_summary.json',
      JSON.stringify(summary, null, 2),
      'query_generation'
    );
  }

  console.log(`‚úÖ G√©n√©ration de requ√™tes termin√©e: ${Object.keys(queryMapping).length} claims trait√©s`);
  console.log(`üìä Synth√®se: ${successfulBatches}/${batches.length} lots r√©ussis, ${fallbackCount} fallbacks utilis√©s`);

  return queryMapping;
}

/**
 * V√©rifie un claim unique via le pipeline complet de fact-checking
 * @param {Object} claim - Le claim √† v√©rifier
 * @param {Array} searchQueries - Les requ√™tes de recherche pour ce claim
 * @param {number} analysisId - ID de l'analyse pour les logs
 * @returns {Promise<Object>} R√©sultat du fact-checking
 */
async function verifySingleClaim(claim, searchQueries, analysisId) {
  console.log(`üîç Fact-checking du claim ${claim.id}: "${claim.text.substring(0, 100)}..."`);
  
  const claimSubfolder = `fact_checking/claim_${claim.id}`;
  
  // Sauvegarder les requ√™tes g√©n√©r√©es
  debugLogService.log(
    analysisId,
    '1_search_queries.json',
    JSON.stringify({ claimId: claim.id, claimText: claim.text, searchQueries }, null, 2),
    claimSubfolder
  );

  try {
    // √âTAPE 1: Priorit√© √† Google Fact Check
    console.log(`üîç √âtape 1: Recherche Google Fact Check pour claim ${claim.id}`);
    const googleResult = await googleFactCheckService.query(claim.text);
    
    if (googleResult) {
      console.log(`‚úÖ Google Fact Check trouv√© pour claim ${claim.id}: ${googleResult.verdict}`);
      
      // Formater le r√©sultat Google
      const result = {
        factCheckStatus: 'COMPLETED',
        verdict: googleResult.verdict,
        verdictReason: `Fact-check existant par ${googleResult.sourceName}: ${googleResult.originalRating}`,
        sources: [
          {
            url: googleResult.sourceUrl,
            title: `${googleResult.sourceName} - Fact Check`
          }
        ]
      };

      // Sauvegarder le r√©sultat Google
      debugLogService.log(
        analysisId,
        '2_google_result.json',
        JSON.stringify({ googleResult, finalResult: result }, null, 2),
        claimSubfolder
      );

      return result;
    }

    console.log(`‚ÑπÔ∏è Aucun fact-check Google trouv√© pour claim ${claim.id}, passage √† la recherche web`);

    // √âTAPE 2: Recherche web via Serper
    console.log(`üîç √âtape 2: Recherche web pour claim ${claim.id}`);
    const searchResults = await webSearchService.searchMultiple(searchQueries);
    
    if (!searchResults || searchResults.length === 0) {
      console.warn(`‚ö†Ô∏è Aucun r√©sultat de recherche pour claim ${claim.id}`);
      
      const result = {
        factCheckStatus: 'COMPLETED',
        verdict: 'UNVERIFIABLE',
        verdictReason: 'Aucune source trouv√©e pour v√©rifier cette affirmation.',
        sources: []
      };

      debugLogService.log(
        analysisId,
        '3_no_search_results.json',
        JSON.stringify({ searchQueries, finalResult: result }, null, 2),
        claimSubfolder
      );

      return result;
    }

    console.log(`‚úÖ ${searchResults.length} r√©sultats de recherche trouv√©s pour claim ${claim.id}`);

    // Sauvegarder les r√©sultats de recherche
    debugLogService.log(
      analysisId,
      '2_search_results.json',
      JSON.stringify({ searchQueries, searchResults }, null, 2),
      claimSubfolder
    );

    // √âTAPE 3: Construire le corpus de preuves
    const evidenceCorpus = searchResults.map(result => 
      `Source: ${result.title}\nURL: ${result.link}\nContenu: ${result.snippet}`
    ).join('\n\n---\n\n');

    // √âTAPE 4: Verdict du LLM Juge
    console.log(`ü§ñ √âtape 3: Analyse LLM pour claim ${claim.id}`);
    const userPrompt = `Affirmation √† v√©rifier: "${claim.text}"

Corpus de Preuves:
${evidenceCorpus}`;

    const factCheckModel = process.env.FACT_CHECK_MODEL || "openai/gpt-4o";
    const maxRetries = parseInt(process.env.LLM_RETRY_COUNT) || 3;
    const retryDelay = parseInt(process.env.LLM_RETRY_DELAY_MS) || 2000;

    const apiCall = async () => {
      const response = await openrouter.chat.completions.create({
        model: factCheckModel,
        messages: [
          { role: "system", content: FACT_CHECK_PROMPT },
          { role: "user", content: userPrompt }
        ],
        response_format: { type: "json_object" },
        timeout: 45000,
      });

      if (!response.choices || response.choices.length === 0) {
        throw new Error("R√©ponse vide de l'API de fact-checking");
      }

      const rawJson = response.choices[0].message.content;
      
      // Sauvegarder la r√©ponse brute
      debugLogService.log(
        analysisId,
        '3_llm_response.txt',
        rawJson,
        claimSubfolder
      );

      const cleanedJson = extractJsonFromString(rawJson);
      
      if (!cleanedJson) {
        throw new Error("Impossible d'extraire un JSON valide de la r√©ponse LLM");
      }

      const llmResult = JSON.parse(cleanedJson);
      
      if (!llmResult.verdict || !llmResult.explanation) {
        throw new Error("Structure JSON invalide dans la r√©ponse LLM");
      }

      return llmResult;
    };

    const llmResult = await callLLMWithRetry(
      apiCall,
      maxRetries,
      retryDelay,
      `Fact-check LLM claim ${claim.id}`
    );

    // Formater le r√©sultat final
    const result = {
      factCheckStatus: 'COMPLETED',
      verdict: llmResult.verdict,
      verdictReason: llmResult.explanation,
      sources: llmResult.sources || []
    };

    console.log(`‚úÖ Fact-checking termin√© pour claim ${claim.id}: ${result.verdict}`);

    // Sauvegarder le r√©sultat final
    debugLogService.log(
      analysisId,
      '4_final_result.json',
      JSON.stringify({ llmResult, finalResult: result }, null, 2),
      claimSubfolder
    );

    return result;

  } catch (error) {
    console.error(`‚ùå Erreur lors du fact-checking du claim ${claim.id}:`, error.message);
    
    const errorResult = {
      factCheckStatus: 'FAILED',
      verdict: 'UNVERIFIABLE',
      verdictReason: `Erreur lors de la v√©rification: ${error.message}`,
      sources: []
    };

    // Sauvegarder l'erreur
    debugLogService.log(
      analysisId,
      '4_error.json',
      JSON.stringify({ error: error.message, finalResult: errorResult }, null, 2),
      claimSubfolder
    );

    return errorResult;
  }
}

/**
 * Fonction principale pour orchestrer le fact-checking d'une analyse compl√®te
 * @param {number} analysisId - ID de l'analyse
 * @param {Array} claimsToFactCheck - Liste des claims √† v√©rifier
 */
async function runFactCheckingForAnalysis(analysisId, claimsToFactCheck) {
  console.log(`üöÄ D√©but du fact-checking pour ${claimsToFactCheck.length} claims de l'analyse ${analysisId}`);
  
  // Mettre √† jour le statut de l'analyse
  await prisma.analysis.update({
    where: { id: analysisId },
    data: {
      status: 'FACT_CHECKING',
      progress: 0
    }
  });

  try {
    // √âTAPE 1: G√©n√©ration des requ√™tes de recherche en lot
    console.log(`üìù G√©n√©ration des requ√™tes de recherche pour ${claimsToFactCheck.length} claims`);
    const searchQueriesMapping = await generateSearchQueries(claimsToFactCheck, analysisId);

    // √âTAPE 2: Cr√©ation des t√¢ches de fact-checking
    const tasks = claimsToFactCheck.map(claim => async () => {
      const searchQueries = searchQueriesMapping[claim.id] || [];
      return await verifySingleClaim(claim, searchQueries, analysisId);
    });

    // √âTAPE 3: Ex√©cution par lots
    const limit = parseInt(process.env.CONCURRENT_CHUNK_LIMIT) || 3;
    let processedClaims = 0;
    const allResults = [];

    console.log(`üöÄ Fact-checking par lots avec une limite de ${limit} claims simultan√©s`);

    for (let i = 0; i < tasks.length; i += limit) {
      const batch = tasks.slice(i, i + limit);
      const batchNumber = Math.floor(i / limit) + 1;
      const totalBatches = Math.ceil(tasks.length / limit);
      
      console.log(`üì¶ Fact-checking du lot ${batchNumber}/${totalBatches} (${batch.length} claims)`);
      
      try {
        const batchResults = await Promise.all(batch.map(task => task()));
        allResults.push(...batchResults);
        
        processedClaims += batch.length;
        
        // Sauvegarder les r√©sultats de ce lot en base
        for (let j = 0; j < batchResults.length; j++) {
          const result = batchResults[j];
          const claim = claimsToFactCheck[i + j];
          
          await prisma.claim.update({
            where: { id: claim.id },
            data: {
              factCheckStatus: result.factCheckStatus,
              verdict: result.verdict,
              verdictReason: result.verdictReason,
              sources: result.sources
            }
          });
        }
        
        // Calculer et mettre √† jour le progr√®s
        const progress = Math.round((processedClaims / tasks.length) * 100);
        
        await prisma.analysis.update({
          where: { id: analysisId },
          data: {
            status: processedClaims < tasks.length ? 'PARTIALLY_COMPLETE' : 'FACT_CHECKING',
            progress: progress
          }
        });
        
        console.log(`‚úÖ Lot de fact-checking ${batchNumber} termin√© - Progr√®s: ${processedClaims}/${tasks.length} claims (${progress}%)`);
        
        // Pause entre les lots pour m√©nager les APIs
        if (i + limit < tasks.length) {
          await sleep(2000);
        }
        
      } catch (error) {
        console.error(`‚ùå Erreur lors du traitement du lot de fact-checking ${batchNumber}:`, error.message);
        processedClaims += batch.length;
      }
    }

    // Cr√©er un rapport global de fact-checking
    const globalReport = {
      totalClaims: claimsToFactCheck.length,
      factCheckModel: process.env.FACT_CHECK_MODEL || "openai/gpt-4o",
      factCheckTimestamp: new Date().toISOString(),
      results: allResults.map((result, index) => {
        const claim = claimsToFactCheck[index];
        return {
          claimId: claim.id,
          claimText: claim.text,
          claimTimestamp: claim.timestamp,
          factCheckResult: result
        };
      })
    };

    debugLogService.log(
      analysisId,
      '4_fact_check_report.json',
      JSON.stringify(globalReport, null, 2)
    );

    console.log(`‚úÖ Fact-checking termin√©: ${allResults.length} claims trait√©s`);

  } catch (error) {
    console.error(`‚ùå Erreur critique lors du fact-checking de l'analyse ${analysisId}:`, error.message);
    
    await prisma.analysis.update({
      where: { id: analysisId },
      data: {
        status: 'FAILED',
        errorMessage: `Erreur de fact-checking: ${error.message}`,
        progress: 0
      }
    });
  }
}

module.exports = {
  runFactCheckingForAnalysis,
  verifySingleClaim,
  generateSearchQueries
};